---
title: "Ejercicio3"
author: "Marta Venegas Pardo"
date: "18/11/2021"
output:
  prettydoc::html_pretty:
    theme: cayman
    highlight: github
    toc: true
    toc_depth: 3
---

```{r setup, include=FALSE}
library(ggplot2)
knitr::opts_chunk$set(echo = TRUE)
set.seed(457367)
```



Estimar el valor de: $$I =
  \int_{0}^{1} 
  \dfrac{e^{- \frac{x^2}{2}}}{\sqrt{x(1-x)}}
  \,dx  \simeq 2,646630906854468$$











Para estimar la primera integral mediante el método de Montecarlo, basta observar que \( I_{1} = \mathbb{E}[g(X)] \), donde \( X \) es una variable uniforme en el intervalo \( (0, 1) \) y \( g(x) = \int_{0}^{1} x^{2}{\sqrt{1-x^{2}}} \mathop{}\!d x \).

1. Establecemos la forma de generar valores aleatorios, en este caso de manera uniforme en el intervalo \((0, 1)\).

2. Definimos la función \( g \) que deberá aplicarse a esos valores aleatorios.




```{r generacion}
genera_valor_aleatorio <- function() {
  runif(1)
}

g<- function(x){
  ( exp(-(x^2)/(2)))/(sqrt(x*(1-x)))
}
```



3. Replicamos el proceso de generar un valor aleatorio y aplicarle la función \( g \). La variable `n` determina la cantidad de replicaciones.

```{r replicacion}
n <- 1e6
valores_g <- replicate(n , {
  x <- genera_valor_aleatorio()
  g(x)
}
)
```

4. Calculamos una estimación de \( I_{1} \) a partir de la media aritmética de los valores obtenidos.


```{r estimacion}
estimacion <- mean(valores_g)
```

El valor estimado de $I$ es $`r estimacion`$. Este método siempre dará
una aproximación, mejor o peor pero se trata de una aproximación.

Puesto que esto es un resultado aleatorio, hay que calcular siempre un
intervalo de confianza que permita acotar la variabilidad de la
estimación.

5. Intervalo de confianza

```{r intervalo-de-confianza}
probabilidad_cobertura <- 0.997
alfa <- 1 - probabilidad_cobertura
percentil<- qnorm(1 - alfa / 2)
error_estandar <- sqrt(var(valores_g)/n)
intervalo_confianza <- estimacion + c(-1,1) * error_estandar * percentil
```

Luego, un intervalo de confianza con probabilidad de cobertura 0.997 es
( $`r intervalo_confianza`$ )


# Reducción de Varianza por Antitéticas


Cáculamos la varianza y la eficiencia del Método de Newton para compararlo con las demás varianzas y eficiencias.

Estimaremos también el coste en tiempo del método haciendo uso de las herramientas proporcionadas por el paquete `bench` (en particular, la función `mark` analiza el coste en tiempo y en memoria de las expresiones proporcionadas, ejecutando cada una de ellas un cierto número de iteraciones y devolviendo una tabla con distintas medidas, entre ellas la mediana de los tiempos de ejecución de cada iteración). De esta forma, podremos estimar la eficiencia del método directo a la hora de estimar el valor de la integral.

```{r Montecarlo-directo, warning=FALSE}
genera_valor_aleatorio <- function() {
  runif(1)
}

pi<- pi
g<- function(x){
  ( exp(-(x^2)/(2)))/(sqrt(x*(1-x)))
}

n <- 1e4
coste_directo <- bench::mark({
  valores_g <- replicate(n, {
    x <- genera_valor_aleatorio()
    g(x)
  })
},
iterations = 10,
time_unit = "ms"
)$median

estimacion_directo <- mean(valores_g)
varianza_directo <- var(valores_g) / n

eficiencia_directo <- 1 / (varianza_directo * coste_directo)
```


A continuación vamos a aplicar el método de las variables antitéticas para tratar de reducir la varianza de la estimación.

```{r generacion-antiteticas}
genera_valores_antiteticas <- function() {
  runif(1)
}



g<- function(x){
  ( exp(-(x^2)/(2)))/(sqrt(x*(1-x)))
}
```

Ahora replicamos el proceso de generar valores antitéticos, aplicarles la función `g` a cada uno de ellos y calcular el promedio. Para que los resultados se puedan comparar con los del método directo, es necesario generar solo `n / 2` pares de valores antitéticos (para que se hayan generado `n` valores aleatorios en total). Haremos también uso del paquete `bench` para estimar el coste en tiempo del método, para poder así estimar su eficiencia a la hora de estimar el valor de la integral.

```{r replicacion-antiteticas, warning=FALSE}
coste_antiteticas <- bench::mark({ # para ver cuanto tarda
  valores <- replicate(n / 2, {
    valores_antiteticos <- genera_valores_antiteticas()
    mean(g(valores_antiteticos)) # (xi + yi) / 2
  })
},
iterations = 10,
time_unit = "ms"
)$median
```

Finalmente, estimamos el valor de la integral, la varianza de esa estimación y la eficiencia del método.

No calculo IC ni nada porque aquí no me interesa, en el examen si tendremos que hacerlo.

```{r estimacion-antiteticas}
estimacion_antiteticas <- mean(valores)
varianza_antiteticas <- var(valores) / (n / 2) # Cuasivar muestral
eficiencia_antiteticas <- 1 / (varianza_antiteticas * coste_antiteticas)
```



La siguiente tabla compara los resultados obtenidos por el método directo de Montecarlo y por el método de las variables antitéticas.

```{r tabla-de-resultados-antiteticas}
knitr::kable(
  data.frame(
    `Método` = c("Directo", "Antitéticas"),
    `Estimación` = c(estimacion_directo, estimacion_antiteticas),
    Varianza = c(varianza_directo, varianza_antiteticas),
    Coste = c(coste_directo, coste_antiteticas),
    Eficiencia = c(eficiencia_directo, eficiencia_antiteticas)
  ),
  digits = 10
)
```

Se puede observar cómo la varianza se reduce en un factor de 10, con un aumento del coste en tiempo que puede llegar a ser considerable. Además, se observa que el método de las antitéticas es menos eficiente que el directo.


# Reducción de la varianza por Muestreo Estratificado:

A continuación vamos a aplicar el método del muestreo estratificado para tratar de reducir la varianza de la estimación.


```{r grafica-g.Est}
library(ggplot2)

ggplot2::ggplot() +
  geom_function(fun = g) +
  xlim(0, 1)
```

La representación gráfica de la función \( g \) muestra que unos estratos adecuados podrían ser los subintervalos \( (0,1/2) \) y \( (1/2,1) \).

## Muestreo estratificado: asignación proporcional


1. En primer lugar definimos los estratos y establecemos la forma de generar valores aleatorios dentro de cada estrato. Una manera simple de definir los estratos es subdividir el intervalo (0, 1) de forma independiente en cada dimensión.

```{r generacion-Mest}
estratos <- data.frame(
  min = c(0, 1/2),
  max = c(1/2, 1),
  probabilidad = c(1/2, 1 / 2)
)
# Función que genera valores dentro de un estrato
genera_valor_en_estrato <- function(numero_estrato) {
  estrato <- estratos[numero_estrato, ]
  runif(1, min = estrato$min, max = estrato$max)
}
```

2. Ahora replicamos el proceso de generar valores en cada estrato, en una cantidad proporcional a su probabilidad, y aplicarles la función `g` a cada uno de ellos. Haremos también uso del paquete `bench` para estimar el coste en tiempo del método, para poder así estimar su eficiencia a la hora de estimar el valor de la integral.

```{r replicacion-proporcionalMest, warning=FALSE}
unidad_de_tiempo <- "ms"
n_estratos <- n * estratos$probabilidad
# Aseguramos valores enteros
n_estratos <- ceiling(n_estratos)
# Aseguramos al menos dos valores en cada estrato
n_estratos <- pmax(n_estratos, 2)

coste_estratificado_proporcional <- bench::mark(
  {
    valores <- lapply(
      seq_len(2), # (1,2), aplico la función 2 veces, una para cada estrato
      function(numero_estrato) {
        replicate(n_estratos[numero_estrato], {
          x <- genera_valor_en_estrato(numero_estrato)
          g(x)
        })
      }
    )
  },
  iterations = 10,
  time_unit = unidad_de_tiempo
)$median
```

Se han generado \( `r n_estratos[1]` \) valores en el primer estrato y \( `r n_estratos[2]` \) valores en el segundo estrato.

3. Finalmente, estimamos el valor de la integral, la varianza de esa estimación y la eficiencia del método.

```{r estimacion-proporcionalMest}
estimacion_estratificado_proporcional <-
  weighted.mean(
    sapply(valores, mean),
    estratos$probabilidad
  )
varianza_estratificado_proporcional <-
  sum(estratos$probabilidad^2 * sapply(valores, var) / n_estratos)
eficiencia_estratificado_proporcional <-
  1 / (varianza_estratificado_proporcional *
    coste_estratificado_proporcional)
```


## Muestreo estratificado: asignación óptima

Consideramos los mismos estratos que antes y, por tanto, la misma forma de generar valores en cada uno de ellos.

Ahora replicamos el proceso de generar en cada estrato una cantidad óptima de valores, determinada mediante un procedimiento en dos etapas, y aplicarles la función `g` a cada uno de ellos. Haremos también uso del paquete `bench` para estimar el coste en tiempo del método, para poder así estimar su eficiencia a la hora de estimar el valor de la integral.

```{r replicacion-optimo, warning=FALSE}
n_tanteo <- 100
n_produccion <- n - n_tanteo # Para que la cantidad total de valores generados sea igual en los tres métodos y, por tanto, su comparación tenga sentido

coste_estratificado_optimo <- bench::mark(
  {
    # Estimación de las varianzas de los estratos
    n_estratos <- pmax(
      ceiling(n_tanteo * estratos$probabilidad), # asignación proporcional para calcular la var
      2
    )
    valores <- lapply(
      seq_len(2),
      function(numero_estrato) {
        replicate(n_estratos[numero_estrato], {
          x <- genera_valor_en_estrato(numero_estrato)
          g(x)
        })
      }
    )

    # Cantidad óptima de valores en cada estrato
    sigmas <- sapply(valores, sd)
    n_estratos <-
      pmax(
        ceiling(n_produccion * estratos$probabilidad * sigmas /
          sum(estratos$probabilidad * sigmas)),
        2
      )

    # Generación de valores en cada estrato
    valores <- lapply(
      seq_len(2),
      function(numero_estrato) {
        replicate(n_estratos[numero_estrato], {
          x <- genera_valor_en_estrato(numero_estrato)
          g(x)
        })
      }
    )
  },
  iterations = 10,
  time_unit = unidad_de_tiempo
)$median
```

Se han generado \( `r n_estratos[1]` \) valores en el primer estrato y \( `r n_estratos[2]` \) valores en el segundo estrato.

Finalmente, estimamos el valor de la integral, la varianza de esa estimación y la eficiencia del método.

```{r estimacion-optimo}
estimacion_estratificado_optimo <-
  weighted.mean(
    sapply(valores, mean),
    estratos$probabilidad
  )
varianza_estratificado_optimo <-
  sum(estratos$probabilidad^2 * sapply(valores, var) / n_estratos)
eficiencia_estratificado_optimo <-
  1 / (varianza_estratificado_optimo *
    coste_estratificado_optimo)
```

La siguiente tabla compara los resultados obtenidos por el método directo de Montecarlo y por el método del muestreo estratificado.

```{r tabla-de-resultados-est}
knitr::kable(
  data.frame(
    `Método` = c(
      "Directo",
     "Estratificado proporcional",
     "Estratificado óptimo"
    ),
    `Estimación` = c(
      estimacion_directo,
     estimacion_estratificado_proporcional,
     estimacion_estratificado_optimo
    ),
    Varianza = c(
      varianza_directo,
     varianza_estratificado_proporcional,
     varianza_estratificado_optimo
    ),
    Coste = c(
      coste_directo,
      coste_estratificado_proporcional,
      coste_estratificado_optimo
    ),
    Eficiencia = c(
      eficiencia_directo,
     eficiencia_estratificado_proporcional,
     eficiencia_estratificado_optimo
    )
  ),
  digits = 10
)
```

Para este problema, la eficiencia del método del muestreo estratificado es mucho menor que la del método directo, ya que la reducción de varianza conseguida es anulada completamente por el aumento del coste en tiempo. En este caso, el Método Estratificado proporcional es mejor, ya que reduce la varianza en un factor de 10 y además es el que menor eficiencia tiene.


